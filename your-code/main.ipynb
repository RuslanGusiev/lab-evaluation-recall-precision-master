{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation: Precision & Recall\n",
    "\n",
    "Using the evaluation metrics we have learned, we are going to compare how well some different types of classifiers perform on different evaluation metrics.\n",
    "\n",
    "We are going to use a dataset of written numbers which we can import from sklearn. Run the code below to do so. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "from sklearn.datasets import fetch_openml\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "mnist = fetch_openml('mnist_784')\n",
    "X, y = mnist['data'], mnist['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now take a look at the shapes of the X and y matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 784)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's pick one entry and see what number is written. Use indexing to pick the 36000th digit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   4., 149.,\n",
       "       255., 184.,  12.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,  11., 133., 212., 253., 253., 253., 102.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0., 162., 236., 253., 253.,\n",
       "       253., 253., 253.,  55.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "        35., 196., 253., 253., 253., 253., 253., 253., 239.,  18.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,  89., 249., 253., 253., 253., 185.,\n",
       "       253., 253., 177.,  24.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 129.,\n",
       "       247., 253., 253., 165., 150., 205., 253., 139.,   3.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,  89., 247., 253., 240., 131.,  85., 221.,\n",
       "       253., 253.,  84.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   4., 187.,\n",
       "       253., 253., 236., 139., 252., 253., 253., 253.,  84.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,  21., 253., 253., 253., 253., 253., 253.,\n",
       "       253., 253., 248.,  53.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  99.,\n",
       "       253., 253., 253., 253., 253., 214., 253., 253., 179.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   4., 186., 251., 253., 249., 172.,\n",
       "       133., 253., 253., 137.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,  49.,  94.,   6.,   0., 212., 253., 253.,  39.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "       126., 253., 253., 197.,   6.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,  27., 234., 253., 253.,  94.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "       100., 253., 253., 239.,  11.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,  61., 249., 253., 253.,  79.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   5.,\n",
       "       109., 253., 253., 193.,   4.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,  66., 253., 253., 253.,  30.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "       147., 253., 253., 182.,   2.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,  99., 248., 253., 222.,  13.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "a = X[36000]\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Use the *reshape(28,28)* method and *plt.imshow()* function with the parameters *cmap = matplotlib.cm.binary* and *interpolation=\"nearest\"* to make a plot of the number. Be sure to import matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x29a5dd15240>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# your code here\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "b = a.reshape((28,28))\n",
    "plt.imshow(b, cmap = plt.cm.binary, interpolation=\"nearest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use indexing to see if what the plot shows matches with the outcome of the 36000th index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'9'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "y[36000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now lets break into a test train split to run a classification. Instead of using sklearn, use indexing to select the first 60000 entries for the training and the rest for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['5', '0', '4', ..., '5', '6', '8'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "X_train = X[:60000]\n",
    "X_test = X[60000:]\n",
    "y_train = y[:60000]\n",
    "y_test = y[60000:]\n",
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We are going to make a two-class classifier, so lets restrict to just one number, for example 5s. Do this by defining a new y training and y testing sets for just the number 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "import numpy as np\n",
    "\n",
    "#y_train = [x for x in y_train if x == '5']\n",
    "#y_test = [x for x in y_test if x == '5']\n",
    "y_train_5 = np.where(y_train == '5', 1, 0)\n",
    "y_test_5 = np.where(y_test == '5', 1, 0)\n",
    "len(y_train_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets train a logistic regression to predict if a number is a 5 or not. Remember to use the 'just 5s' target train array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train_5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Does the classifier predict correctly the 36000th digit we picked before?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "clf.predict(X[36000].reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your comments here\n",
    "# 9  != 5. Thats why the output is 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The 35th value is a 5. Check if it was correctly predicted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "clf.predict(X[35].reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your comments here\n",
    "# the 35th element ==5. So we have result 1 and it is a True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To make some comparisons, we are going to make a very dumb classifier, that never predicts 5s. Build the classifier with the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "from sklearn.base import BaseEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dumb classifier\n",
    "class Never5Classifier(BaseEstimator):\n",
    "    def fit(self, X, y=None):\n",
    "        pass\n",
    "    def predict(self, X):\n",
    "        return np.zeros((len(X), 1))[:, 0]\n",
    "\n",
    "never_5_clf = Never5Classifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now lets fit and predict on the testing set using our dumb classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "never_5_clf.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "never_5_clf.predict(X[36000].reshape(1, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's compare this to the Logistic Regression. Examine the confusion matrix, precision, recall, and f1_scores for each. What is the probability cutoff you are using to decide the classes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic regresson: \n",
      " [[9027   81]\n",
      " [ 145  747]]\n",
      "Never5Classifier: \n",
      " [[9108    0]\n",
      " [ 892    0]]\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_pred_test_rf = clf.predict(X_test)\n",
    "\n",
    "print('logistic regresson: \\n',confusion_matrix(y_test_5, y_pred_test_rf) )\n",
    "\n",
    "y_pred_test_rf1 = never_5_clf.predict(X_test)\n",
    "\n",
    "print('Never5Classifier: \\n',confusion_matrix(y_test_5, y_pred_test_rf1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.9768750905402074, 0.9774, 0.9770190972469596)\n",
      "(0.82955664, 0.9108, 0.8682820180029306)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "print(precision_recall_fscore_support(y_test_5, y_pred_test_rf, average='weighted')[0:3])\n",
    "\n",
    "\n",
    "print(precision_recall_fscore_support(y_test_5, y_pred_test_rf1, average='weighted')[0:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What are the differences you see? Without knowing what each model is, what can these metrics tell you about how well each works?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here\n",
    "# The logistic regression works better and makes less number of mistakes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now let's examine the roc_curve for each. Use the roc_curve method from sklearn.metrics to help plot the curve for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Never5')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# your code here\n",
    "fpr_log, tpr_log, _ = metrics.roc_curve(y_test_5, y_pred_test_rf)\n",
    "fpr_never, tpr_never, _ = metrics.roc_curve(y_test_5, y_pred_test_rf1)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "ax[0].plot(fpr_log,tpr_log)\n",
    "ax[0].set_title('Logistic Regression')\n",
    "ax[1].plot(fpr_never,tpr_never)\n",
    "ax[1].set_title('Never5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now find the roc_auc_score for each. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc Logistic Regression 0.914275332777965\n",
      "auc Logistic Regression 0.5\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "auc_log = metrics.roc_auc_score(y_test_5, y_pred_test_rf)\n",
    "print('auc Logistic Regression', auc_log)\n",
    "\n",
    "auc_never = metrics.roc_auc_score(y_test_5, y_pred_test_rf1)\n",
    "print('auc Logistic Regression', auc_never)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What does this metric tell you? Which classifier works better with this metric in mind?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here\n",
    "# The logistic regression works better with metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
